{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "### 1. Predicting Survived\n",
    "##### 1.1 Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(12356)\n",
    "df = pd.read_csv(\"malnutrition-estimates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ISO code', 'Country', 'Survey Year', 'Year',\n",
       "       'Income Classification', 'LDC', 'LIFD', 'LLDC or SID2',\n",
       "       'Survey Sample (N)', 'Severe Wasting', 'Wasting', 'Overweight',\n",
       "       'Stunting', 'Underweight', 'Notes', 'Report Author', 'Source',\n",
       "       'Short Source', 'U5 Population ('000s)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 1.2 Assign input and output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assign input variables\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncome Classification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSevere Wasting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWasting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverweight\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assign target variable\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStunting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "# Assign input variables\n",
    "X = df.loc[:,[\"Income Classification\",\"Severe Wasting\",\"Wasting\",\"Overweight\"]]\n",
    "\n",
    "# Assign target variable\n",
    "y = df['Stunting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Handle some missing and fix variables types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values by the median\n",
    "#X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "\n",
    "# Impute the Embarked variable\n",
    "#X[\"Embarked\"] = X[\"Embarked\"].fillna(\"S\")\n",
    "# Change Pclass to categorical variable\n",
    "#X['Pclass'] = X['Pclass'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Encode categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 1.5 Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m x_train,x_test,y_train,y_test\u001b[38;5;241m=\u001b[39mtrain_test_split(X,y,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6 Setup and Train a gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "r1 = GradientBoostingClassifier(n_estimators=100, learning_rate=1)\n",
    "r1.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "ypred_test = r1.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(ypred_test, y_test)\n",
    "print('===============')\n",
    "print('Confusion Matrix:')\n",
    "print(mat)\n",
    "print('===============')\n",
    "print('Testing Accuracy:')\n",
    "print(mat.diagonal().sum()/mat.sum())\n",
    "print('===============')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m sorted_idx \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mr1\u001b[38;5;241m.\u001b[39mfeature_importances_)\u001b[38;5;241m.\u001b[39margsort()\n\u001b[0;32m      6\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariables\u001b[39m\u001b[38;5;124m'\u001b[39m:x_train\u001b[38;5;241m.\u001b[39mcolumns[sorted_idx], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m:r1\u001b[38;5;241m.\u001b[39mfeature_importances_[sorted_idx]})\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m feature_importance[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r1' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sorted_idx = (-r1.feature_importances_).argsort()\n",
    "\n",
    "feature_importance = pd.DataFrame({'Variables':x_train.columns[sorted_idx], 'Importance':r1.feature_importances_[sorted_idx]})\n",
    "df = feature_importance[:10]\n",
    "df.sort_values('Importance',inplace=True)\n",
    "\n",
    "df.plot(kind='barh',y='Importance',x='Variables', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Training Accuracy of gradient boosting with n_estimators running from n1 to n2 \n",
    "# and two learning rates l1 and l2. \n",
    "\n",
    "n1 = 1\n",
    "n2 = 100\n",
    "l1 = .1\n",
    "l2 = 1\n",
    "\n",
    "ac = pd.DataFrame([], columns=list(['Rounds','Learning Rate','Accuracy']))\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for rs in range(n1, n2):\n",
    "    for lr in [l1, l2]:\n",
    "        boost = GradientBoostingClassifier(n_estimators=rs, learning_rate=lr)\n",
    "        boost.fit(x_train,y_train)\n",
    "        ac = pd.concat([ac, pd.DataFrame([[rs, lr, boost.score(x_train,y_train)]], \n",
    "                                    columns=list(['Rounds','Learning Rate','Training Accuracy']))], \n",
    "                       ignore_index=True)\n",
    "        \n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "ax = sns.lineplot(x=\"Rounds\", y=\"Training Accuracy\", \n",
    "                  hue =ac['Learning Rate'].astype('category'),data=ac)\n",
    "ax.text(x=0.5, y=1.1, s='Learning fast vs. Learning slow', \n",
    "        fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Training Accuracy of gradient boosting with n_estimators running from n1 to n2 \n",
    "# and two learning rates l1 and l2. \n",
    "\n",
    "n1 = 1\n",
    "n2 = 100\n",
    "l1 = .1\n",
    "l2 = 1\n",
    "\n",
    "ac = pd.DataFrame([], columns=list(['Rounds','Learning Rate','Accuracy']))\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for rs in range(n1, n2):\n",
    "    for lr in [l1, l2]:\n",
    "        boost = GradientBoostingClassifier(n_estimators=rs, learning_rate=lr)\n",
    "        boost.fit(x_train,y_train)\n",
    "        ac = pd.concat([ac, pd.DataFrame([[rs, lr, boost.score(x_test,y_test)]], \n",
    "                                    columns=list(['Rounds','Learning Rate','Test Accuracy']))], \n",
    "                       ignore_index=True)\n",
    "        \n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "ax = sns.lineplot(x=\"Rounds\", y=\"Test Accuracy\", \n",
    "                  hue =ac['Learning Rate'].astype('category'),data=ac)\n",
    "ax.text(x=0.5, y=1.1, s='Learning fast vs. Learning slow', \n",
    "        fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Practice\n",
    "\n",
    "Predicting Breast Cancer.\n",
    "\n",
    "1. Import the breast cancer dataset. The data can be downloaded at this [link](https://bryantstats.github.io/math460/python/breast_cancer.csv)\n",
    "\n",
    "2. Set the input (X) and output (y) (Use `df.columns` to see all the columns to easier copy/paste). Split the data into 60% training and 40% testing\n",
    "\n",
    "3. Train a gradient boosting model with 200 n_estimators and .1 learning rare. What is testing accuracy of the gradient boosting?\n",
    "\n",
    "4. What is the most important variable according to the above gradient boosting model in predicting breast cancer?\n",
    "\n",
    "5. Find a gradient boosting (try a few different of `n_estimators` and `learning_rate`) that have a higher testing accuracy than the above gradient boosting. What is the n_estimators and learning of this gradient boosting? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
